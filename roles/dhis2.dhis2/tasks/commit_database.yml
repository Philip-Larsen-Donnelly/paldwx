---
- file:
    path: "{{ storage }}/tmp"
    owner: "{{ postgresql_user }}"
    group: "{{ postgresql_user }}"
    recurse: yes
    state: "directory"

# download the demo db (if not empty param)
- name: get the current date time
  set_fact: db_snap_date="{{lookup('pipe','date \"+%Y-%m-%d_%H%M%S\"')}}"

- name: store db commit format
  set_fact:
    commit_dump_format: "{{ 'pgc' if instance.db_demo is regex('.*pgc') else 'sql.gz' }}"
  when:
    - favour_pgc_format|default(false)|bool == false

- name: force db commit format to pgc
  set_fact:
    commit_dump_format: "pgc"
  when:
    - favour_pgc_format|default(false)|bool

- name: Dump database snapshot (without analytics) to a file (with compression)
  postgresql_db:
    name: "{{ instance.db_name }}"
    port: "{{ postgresql_port_map[instance.postgresql_version] | default(omit) }}"
    state: dump
    target: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.{{ commit_dump_format }}"
    target_opts: "{{ dump_cluster }} {{ dump_options }}"
  become: true
  become_user: "{{ postgresql_user }}"
  vars:
    ansible_ssh_pipelining: true
    dump_options: "{{ '-Fc -Z 9 --no-owner --no-privileges -T analytics* -T _*' if (commit_dump_format == 'pgc') else '--no-owner --no-privileges -T analytics* -T _*' }}"
    dump_cluster: "--cluster {{instance.postgresql_version | default(postgresql_version)}}/main"
  when: instance.db_demo is defined and instance.db_demo|length
  # not sure I need the "when" above - it might prevent snapshotting an instance started from empty.


- name: commit the snapshot to s3
  aws_s3:
    aws_access_key: "{{ aws_access_key }}"
    aws_secret_key: "{{ aws_secret_key }}"
    bucket: "{{ dhis2_project_database_bucket }}"
    object: "{{ instance.db_demo | replace('sql.gz', commit_dump_format) }}"
    src: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.{{ commit_dump_format }}"
    mode: put
    metadata:
      saved_by: "{{ awx_user_name | default('unknown') }}"
      comment: "{{ db_commit_comment | default('none') }}"
      original_source: "{{ instance.db_demo }}"
      war_file: "{{ instance.war_file }}"

- name: copy the commited DB to s3 latest too when managing demo DBs.
  aws_s3:
    aws_access_key: "{{ aws_access_key }}"
    aws_secret_key: "{{ aws_secret_key }}"
    bucket: "{{ dhis2_project_database_bucket }}"
    object: "{{ (project+'/'+item+'/dhis2-db-sierra-leone.sql.gz') }}"
    src: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.{{ commit_dump_format }}"
    mode: put
    metadata:
      saved_by: "{{ awx_user_name | default('unknown') }}"
      comment: "{{ db_commit_comment | default('none') }}"
      original_source: "{{ instance.db_demo }}"
      war_file: "{{ instance.war_file }}"
  when:
    - project == "sierra-leone"
    - item is defined
    - (project+'/'+item+'/dhis2-db-sierra-leone.sql.gz') != instance.db_demo
  with_items:
    - "{{Â dhis2_demo_to_dev[instance.name] }}"


- name: Create a tar.gz archive of the instance filestore.
  block:

  - name: create the archive
    community.general.archive:
      path: "{{ storage }}/instances/{{ instance.name }}/home/dhis2-{{ instance.db_name|replace('_','-')  }}-store/*"
      dest: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.filestore"
      format: gz
      force_archive: true
    ignore_errors: yes


  - name: commit the filestore to s3
    aws_s3:
      aws_access_key: "{{ aws_access_key }}"
      aws_secret_key: "{{ aws_secret_key }}"
      bucket: "{{ dhis2_project_database_bucket }}"
      object: "{{ instance.db_demo | replace('sql.gz', 'filestore') | replace('.pgc', '.filestore') }}"
      src: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.filestore"
      mode: put
      metadata:
        saved_by: "{{ awx_user_name | default('unknown') }}"
        comment: "{{ db_commit_comment | default('none') }}"
        original_source: "{{ instance.db_demo }}"
        war_file: "{{ instance.war_file }}"
    ignore_errors: yes

  when: dhis2_filestore.type | default('filesystem') == 'filesystem'


- name: remove local dump file
  file:
    path: "{{ storage }}/tmp/{{ db_snap_date }}_{{ instance.name }}.*"
    state: absent


- name: update the facts if format was forced
  block:

  - name: update the facts with correct DB format (if necessary)
    lineinfile:
      dest: "{{ storage }}/instances/{{ instance.name }}/home/instance.fact"
      regexp: "^db_demo=.+$"
      line: "db_demo={{ instance.db_demo | replace('sql.gz',commit_dump_format) }}"


  - name: update the facts
    set_fact:
      instance_update: "{{ instance_update | default(instance) | combine({item.name: item.value}) }}"
    with_items:
      - { name: db_demo , value: "{{ instance.db_demo | replace('sql.gz',commit_dump_format) }}" }

  - name: update displayed facts
    include: factualise_instance.yml

  when: (instance.db_demo | replace('sql.gz',commit_dump_format) ) != instance.db_demo
